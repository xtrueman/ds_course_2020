# Лабораторная работа №2: Pandas

1. Считать в pandas DataFrame любой источник данных: любой CSV, JSON, Excel-файл, HTML-таблицу, данные из любой СУБД куда у вас есть доступ и т.п.
Также можно сконвертировать в dataframe любой из встроенных датасетов sklearn: (см. [инструкцию](https://stackoverflow.com/questions/38105539/how-to-convert-a-scikit-learn-dataset-to-a-pandas-dataset))
Одним словом загружаете данные откуда угодно, куда можете дотянуться.
Главное условие к датасету, который вы загружаете — там должны быть числовые колонки (по сути численные признаки).

2. Совершаете с датафреймом следующие операции:
  1. `.head()`
  2. `.describe()`
  3. считайте значение конкретной ячейки (с конкретным индексом из конкретной колонки)
  4. фильтрация строк по диапазону индекса
  5. фильтрация набора данных по какому-либо условию
  6. работа с пропущенными значениями (если они есть): удаление строк с пропущенными значениями, заполнение пропущенных значений средним значением по колонке. Если пропущенных значений нет — намеренно их "генерируете", прибивая какие-то куски данных в np.nan
  7. создание нового поля вычисленного на основе значений других полей:
    1. через выражение на базе имеющихся колонок,
    2. через `DataFrame.apply`
    3. через `Series.apply`
  8. сортировка по какому-либо из полей
  9. вычислить несколько статистик по колонкам (используйте встроенные агрегатные функции — любые на выбор)
  10. По какому-либо полю / набору полей смотрим число значений с помощью `.value_counts()`
  11. Если значений немного — вывод уникальных значений какой-либо колонки через `.unique()`
  12. Удалите текущий индекс и создайте новый индекс на базе новой колонки, которая для этого лучше всего подходит

3. Продемонстрировать работу `.groupby`, на основе группировок в groupby вычисляете агрегатные функции по одной или нескольким колонкам

4. Решейпинг данных 1Dto2D с помощью `.pivot` (можно подать на вход результаты агрегатов, полученных ранее через `.groupby` (сгруппировать по двум полям), либо прекрасно заходит сюда данные из SQL сгруппированные предварительно по 2-м полям) 

5. Решейпинг 1Dto2D данных соединённый с группировкой / агрегацией (одним словом — сводная таблица): `.pivot_table`. Группируем только по категориальным полям или числовым, если уверены, что значений немного! Если значений много, можете вначале из загрубить (см. (2.7.) либо (7)) 

6. Посчитать квантили распределения какого-либо вещественного признака (с помощью `numpy.quantile` или `numpy.percentile`) 

7. Посчитать (в виде текста) гистограмму какого-либо вещественного признака (с помощью `numpy.histogram`). Значения гистограммы можете использовать как вариант в качестве загрубленного числового признака для заданий (4) или (5).

8. Получить `DataFrame` с `MultiIndex` любым способом: через конструктор (в документации увидите множество видов конструкторов для создания MultiIndex с нуля), через `read_sql` / `read_csv` / `read_excel`, `read_*`, через `pivot_table`, через `groupby` или иными способами.
  1. Переставить местами уровни индекса
  2. Транспонировать таблицу (или создать новую другую) с MultiIndex
  3. Удалить один из уровней индекса или добавить новый уровень индекса (можно инициализированный константой) — посмотрите сами в документации как это делать

9. Продемонстировать работу `.merge`
10. Продемонстрировать работу с `.concat` или `append`
11. Проитерировать dataframe построчно `.iterrows()` и что-то "полезное" сделайте внутри цикла
